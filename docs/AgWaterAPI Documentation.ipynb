{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1675d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "AGRIMET_DATA_DIR = \"d:/Websites/AgWaterAPI/agrimet/histEtSummaries\"\n",
    "\n",
    "cropCodes = {\n",
    "    \"ALFA\": \"Alfalfa\",\n",
    "    \"ALFM\": \"Alfalfa (Mean)\",\n",
    "    \"ALFN\": \"Alfalfa (New Plant)\",\n",
    "    \"ALFP\": \"Alfalfa (Peak)\",\n",
    "    \"APPL\": \"Apples\",\n",
    "    \"ASPA\": \"Asparagus\",\n",
    "    \"BEAN\": \"Dry Beans\",\n",
    "    \"BEET\": \"Sugar Beets\",\n",
    "    \"BLGR\": \"Bluegrass Seed\",\n",
    "    \"BLUB\": \"Blueberries\",\n",
    "    \"BROC\": \"Broccoli\",\n",
    "    \"CABG\": \"Cabbage\",\n",
    "    \"CGRP\": \"Concord Grapes\",\n",
    "    \"CHRY\": \"Cherries\",\n",
    "    \"CRAN\": \"Cranberries\",\n",
    "    \"CRTS\": \"Carrot Seed\",\n",
    "    \"FCRN\": \"Field Corn\",\n",
    "    \"GARL\": \"Garlic\",\n",
    "    \"GRSD\": \"Grass Seed\",\n",
    "    \"HAYP\": \"Fescue Grass Hay (Peak Daily Consumptive Use for Mature Grass Hay)\",\n",
    "    \"HAYM\": \"Fescue Grass Hay (Mean Annual Use with 3 Seasonal Cuttings)\",\n",
    "    \"HOPS\": \"Hops\",\n",
    "    \"LAWN\": \"Lawn\",\n",
    "    \"LILY\": \"Easter Lilies\",\n",
    "    \"MELN\": \"Melons\",\n",
    "    \"NMNT\": \"New Mint\",\n",
    "    \"ONYN\": \"Onion\",\n",
    "    \"ORCH\": \"Orchards\",\n",
    "    \"PAST\": \"Pasture\",\n",
    "    \"PEAR\": \"Pears\",\n",
    "    \"PEAS\": \"Peas\",\n",
    "    \"PECH\": \"Peaches\",\n",
    "    \"POP1\": \"First Year Poplar Trees\",\n",
    "    \"POP2\": \"Second Year Poplar Trees\",\n",
    "    \"POP3\": \"Third Year + Poplar Trees\",\n",
    "    \"POTA\": \"Potatoes\",\n",
    "    \"POTS\": \"Potatoes (Shepody)\",\n",
    "    \"PPMT\": \"Peppermint\",\n",
    "    \"RAPE\": \"Rapeseed (Canola)\",\n",
    "    \"SAFL\": \"Safflower\",\n",
    "    \"SPMT\": \"Spearmint\",\n",
    "    \"SBAR\": \"Spring Barley\",\n",
    "    \"SBRY\": \"Strawberry\",\n",
    "    \"SCRN\": \"Sweet Corn\",\n",
    "    \"SGRN\": \"Spring Grain\",\n",
    "    \"SPMT\": \"Spearmint\",\n",
    "    \"TBER\": \"Trailing Berries\",\n",
    "    \"WGRN\": \"Winter Grain\",\n",
    "    \"WGRP\": \"Wine Grape\"\n",
    "}\n",
    "\n",
    "etCols = [\n",
    "        \"Daily Penman ET (in)-4\",\n",
    "        \"Daily Penman ET (in)-3\",\n",
    "        \"Daily Penman ET (in)-2\",\n",
    "        \"Daily Penman ET (in)-1\",\n",
    "        \"Daily Penman ET (in)\"\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_crop_water_use(station):\n",
    "    \"\"\"\n",
    "    Retrieves the past five days of Crop ET for the given station (all crops for that station).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        url = f\"https://www.usbr.gov/pn/agrimet/chart/{station}ch.txt\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        content = response.text\n",
    "        # Split the content into lines and filter out comment lines (starting with #)\n",
    "        data = [line for line in content.splitlines() if line.strip() and not line.strip().startswith('#')]\n",
    "\n",
    "        data = data[12:]  # Skip the header line s\n",
    "        # Extract every other line, starting with the first\n",
    "        data = data[::2]\n",
    "\n",
    "        # Split each line using '*' as a delimiter and strip whitespace from each part\n",
    "        data = [line.split('*') for line in data]\n",
    "        data = [line[1:] for line in data]\n",
    "\n",
    "        # for each line, flatten the line\n",
    "        # and split by whitespace to get individual data points\n",
    "        _data = []\n",
    "        for line in data:\n",
    "            line = ' '.join(line).strip()\n",
    "            _data.append(line.split())\n",
    "\n",
    "        # Optionally, convert to a pandas DataFrame for structured data\n",
    "        df = pd.DataFrame(_data, columns= ['CropCode','Start Date', 'Daily Penman ET (in)-4',\n",
    "                                    'Daily Penman ET (in)-3', 'Daily Penman ET (in)-2',\n",
    "                                    'Daily Penman ET (in)-1', 'Daily Penman ET (in)',\n",
    "                                    'Cover Date', 'Term Date', 'Sum ET (in)', '7 Day Use', '14 Day Use'],\n",
    "                                     )\n",
    "        cropNames = df['CropCode'].map(cropCodes).fillna(df['CropCode'])  # Map crop codes to names\n",
    "        df['Name'] = cropNames    \n",
    "\n",
    "        #print(df)\n",
    "       \n",
    "        crops = []\n",
    "        for index, row in df.iterrows():\n",
    "            _crop = {}\n",
    "            _crop['cropCode'] = row['CropCode']\n",
    "            _crop['name'] = row['Name']\n",
    "            _crop['startDate'] = row['Start Date']\n",
    "            _crop['coverDate'] = row['Cover Date']\n",
    "            _crop['termDate'] = row['Term Date']\n",
    "            _crop['sumET'] = row['Sum ET (in)']\n",
    "            _crop['7DayUse'] = row['7 Day Use']\n",
    "            _crop['14DayUse'] = row['14 Day Use']\n",
    "            crops.append(_crop)\n",
    "            \n",
    "        dates = []\n",
    "        today = datetime.today()\n",
    "        for i in range(4, -1, -1):\n",
    "            date = today - timedelta(days=i)\n",
    "            dates.append(date.strftime('%m/%d'))            \n",
    "         \n",
    "        #print(dates)\n",
    "           \n",
    "        # create chart data\n",
    "        dfHistET = pd.DataFrame()\n",
    "        stationETSummaries = get_station_summary_data(station.lower(), dates[0], dates[4])\n",
    "        if stationETSummaries:\n",
    "            # the stationETSummaries data to the dataframe, appending the string \"histET\" to each column name\n",
    "            #print(stationETSummaries['crops'])\n",
    "            cropETs = []\n",
    "            for crop in stationETSummaries['crops']:\n",
    "                # find the crop in the 'data' array of dictionaries\n",
    "                data = stationETSummaries['data']\n",
    "        \n",
    "                cropETs = [item[crop] for item in data if crop in item and item[crop] is not None]\n",
    "        \n",
    "        \n",
    "                #for item in data:\n",
    "                #    if crop in item:\n",
    "                #        if item['APPL'] is not None:                 \n",
    "                #            print(crop, stationETSummaries['data'][crop])\n",
    "                if len(cropETs) < 5:\n",
    "                    # If there are not enough data points, fill with None\n",
    "                    #cropETs = cropETs + [None] * (5 - len(cropETs))\n",
    "                    print(f\"Not enough data for {crop}, filling with None\")\n",
    "                dfHistET[crop + \" histET\"] = cropETs\n",
    "                \n",
    "        #print(df['APPL_histET'])\n",
    "\n",
    "        # each column in the data we are gnerating  is a crop, each row (observation)  is a date\n",
    "        chartData = []\n",
    "        for day in range(0,5):\n",
    "            rowData = {}\n",
    "            rowData['Date'] = dates[day]  #.strftime('%m/%d') #.toLocaleDateString('en-US', { month: '2-digit', day: '2-digit' });\n",
    "            for index, row in df.iterrows():  # cwuData.current.forEach(crop => {\n",
    "                cropName = row['Name']\n",
    "                _etCol = etCols[day]\n",
    "                et = row[_etCol]\n",
    "                rowData[cropName] = et\n",
    "\n",
    "            chartData.append(rowData)\n",
    "            \n",
    "        # Convert DataFrame to JSON\n",
    "        #logger.info(chartData)\n",
    "        content = df.to_json(orient='records')\n",
    "            \n",
    "        return { 'crops': crops, 'dates': dates, 'cwuData': chartData}\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {}\n",
    "\n",
    "\n",
    "def get_station_summary_data(station_id, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Retrieve summary ET data for a station within a specified date range.\n",
    "    \n",
    "    Args:\n",
    "        station_id (str): The station ID (e.g., 'abei', 'bfgi')\n",
    "        start_date (str or date): Start date in 'MM/DD' format or date object\n",
    "        end_date (str or date): End date in 'MM/DD' format or date object\n",
    "        summaries_dir (str): Directory containing the summary CSV files\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Dictionary containing:\n",
    "            - 'station_id': The station identifier\n",
    "            - 'date_range': Tuple of (start_date, end_date)\n",
    "            - 'crops': List of available crop types\n",
    "            - 'data': List of dictionaries, each containing date and crop ET values\n",
    "            - 'metadata': Dictionary with file metadata (if available)\n",
    "            \n",
    "    Raises:\n",
    "        FileNotFoundError: If the station summary file doesn't exist\n",
    "        ValueError: If date format is invalid\n",
    "        \n",
    "    Example:\n",
    "        >>> data = get_station_summary_data('abei', '06/01', '06/10')\n",
    "        >>> print(f\"Found {len(data['data'])} days of data\")\n",
    "        >>> for day in data['data']:\n",
    "        ...     print(f\"{day['DATE']}: ALFM={day['ALFM']}, BEET={day['BEET']}\")\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(__name__)   \n",
    "    # Construct file path\n",
    "    summary_file = os.path.join(AGRIMET_DATA_DIR, f\"{station_id}_summary.csv\")\n",
    "\n",
    "    if not os.path.exists(summary_file):\n",
    "        logger.error(f\"Summary file not found: {summary_file}\")\n",
    "        raise FileNotFoundError(f\"Summary file not found: {summary_file}\")\n",
    "    \n",
    "    # Parse date inputs\n",
    "    if isinstance(start_date, str):\n",
    "        start_month, start_day = map(int, start_date.split('/'))\n",
    "    else:\n",
    "        start_month, start_day = start_date.month, start_date.day\n",
    "        \n",
    "    if isinstance(end_date, str):\n",
    "        end_month, end_day = map(int, end_date.split('/'))\n",
    "    else:\n",
    "        end_month, end_day = end_date.month, end_date.day\n",
    "    \n",
    "    # Read the CSV file\n",
    "    metadata = {}\n",
    "    crops = []\n",
    "    data_rows = []\n",
    "    \n",
    "    with open(summary_file, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        # Parse metadata from comment lines and find data start\n",
    "        data_start_idx = 0\n",
    "        for i, line in enumerate(lines):\n",
    "            line = line.strip()\n",
    "            if line.startswith('#'):\n",
    "                if ',' in line:\n",
    "                    key, value = line[1:].split(',', 1)\n",
    "                    metadata[key.strip()] = value.strip()\n",
    "            elif line and not line.startswith('#'):\n",
    "                # Found the header line\n",
    "                data_start_idx = i\n",
    "                break\n",
    "        \n",
    "        # Parse header and data\n",
    "        csv_reader = csv.DictReader(lines[data_start_idx:])\n",
    "        crops = [col for col in csv_reader.fieldnames if col != 'DATE']\n",
    "        \n",
    "        # Filter data by date range\n",
    "        for row in csv_reader:\n",
    "            row_date = row['DATE']\n",
    "            if not row_date:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                month, day = map(int, row_date.split('/'))\n",
    "                \n",
    "                # Check if date is in range (handle year boundary)\n",
    "                in_range = False\n",
    "                if start_month <= end_month:\n",
    "                    # Same year range (e.g., 06/01 to 08/15)\n",
    "                    if start_month <= month <= end_month:\n",
    "                        if month == start_month and day < start_day:\n",
    "                            continue\n",
    "                        if month == end_month and day > end_day:\n",
    "                            continue\n",
    "                        in_range = True\n",
    "                else:\n",
    "                    # Cross year boundary (e.g., 11/15 to 03/15)\n",
    "                    if month >= start_month or month <= end_month:\n",
    "                        if month == start_month and day < start_day:\n",
    "                            continue\n",
    "                        if month == end_month and day > end_day:\n",
    "                            continue\n",
    "                        in_range = True\n",
    "                \n",
    "                if in_range:\n",
    "                    # Clean up the row data - convert empty strings to None\n",
    "                    clean_row = {'DATE': row_date}\n",
    "                    for crop in crops:\n",
    "                        value = row.get(crop, '').strip()\n",
    "                        if value and value != '':\n",
    "                            try:\n",
    "                                clean_row[crop] = float(value)\n",
    "                            except ValueError:\n",
    "                                clean_row[crop] = None\n",
    "                        else:\n",
    "                            clean_row[crop] = None\n",
    "                    data_rows.append(clean_row)\n",
    "                    \n",
    "            except ValueError:\n",
    "                logger.warning(f\"Invalid date format in row: {row_date}, skipping row.\")\n",
    "                # Skip rows with invalid date format\n",
    "                continue\n",
    "    \n",
    "    return {\n",
    "        'station_id': station_id,\n",
    "        'date_range': (start_date, end_date),\n",
    "        'crops': crops,\n",
    "        'data': data_rows,\n",
    "        'metadata': metadata\n",
    "    }\n",
    "\n",
    "get_crop_water_use('crvo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1204522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['07/10', '07/11', '07/12', '07/13', '07/14']\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "res = get_crop_water_use('crvo')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1187c491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPL: 0.185\n"
     ]
    }
   ],
   "source": [
    "data = [{'DATE': '06/01', 'ALFM': 0.166, 'ALFP': 0.194, 'APPL': 0.185, 'BETS': 0.119, 'BLUB': 0.194, 'CBBG': 0.128, 'FCRN': 0.076, 'GRSD': 0.152, 'HZLN': 0.217, 'LAWN': 0.156, 'PEAS': 0.185, 'POP1': 0.084, 'POP2': 0.145, 'POP3': 0.202, 'POTA': 0.118, 'PPMT': 0.182, 'SBRY': 0.185, 'SGRN': 0.194, 'SPNC': 0.116, 'SQSH': 0.081, 'TBER': 0.192, 'WGRN': 0.194, 'WGRP': 0.124}]\n",
    "#_data = next((item for item in data if item[\"name\"] == \"APPL\"), None)\n",
    "\n",
    "\n",
    "for item in data:\n",
    "    if 'APPL' in item:\n",
    "        if item['APPL'] is not None:\n",
    "            print(f\"APPL: {item['APPL']}\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eaa94a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  siteid                                        description state   latitude  \\\n",
      "0   abei                    Aberdeen, Idaho Weather Station    ID  42.953333   \n",
      "1   acki           INL - Blackfoot,  Idaho  Weather Station    ID  43.189850   \n",
      "2   afty             Afton, Wyoming AgriMet Weather Station    WY  42.733330   \n",
      "3   agko  Agency Lake Ranch, Oregon AgriMet Weather Station    OR  42.565270   \n",
      "4   ahti              Ashton, Idaho AgriMet Weather Station    ID  44.025000   \n",
      "\n",
      "   longitude  elevation     timezone    install  horizontal_datum  \\\n",
      "0 -112.82667   1341.000  US/Mountain  3/20/1991               NaN   \n",
      "1 -112.33320   1377.696  US/Mountain        NaN               NaN   \n",
      "2 -110.93583   1892.810  US/Mountain  11/1/1980               NaN   \n",
      "3 -121.98250   1264.920   US/Pacific   5/3/2000               NaN   \n",
      "4 -111.46666   1615.440  US/Mountain   6/1/1987               NaN   \n",
      "\n",
      "  vertical_datum  ...  elevation_method tz_offset  active_flag     type  \\\n",
      "0              m  ...       agrimet_map       NaN          NaN  agrimet   \n",
      "1              m  ...       agrimet_map       NaN          NaN  agrimet   \n",
      "2              m  ...       agrimet_map       NaN          NaN  agrimet   \n",
      "3              m  ...       agrimet_map       NaN          NaN  agrimet   \n",
      "4              m  ...       agrimet_map       NaN          NaN  agrimet   \n",
      "\n",
      "  responsibility Unnamed: 16  Unnamed: 17  Unnamed: 18  Unnamed: 19  \\\n",
      "0           noaa         NaN          NaN          NaN          NaN   \n",
      "1           noaa         NaN          NaN          NaN          NaN   \n",
      "2           pnro         NaN          NaN          NaN          NaN   \n",
      "3           pnro         NaN          NaN          NaN          NaN   \n",
      "4           pnro         NaN          NaN          NaN          NaN   \n",
      "\n",
      "   Unnamed: 20  \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def agrimet_locations():    \n",
    "    \"\"\"\n",
    "    Returns a list of Agrimet locations in CSV format.\n",
    "    \"\"\"    \n",
    "    # Define the URL for the Agrimet locations CSV\n",
    "    agrimet_locations_url = \"https://www.usbr.gov/pn/agrimet/location.csv\"\n",
    "    df = pd.read_csv(agrimet_locations_url, skiprows=1)  # Read the CSV file into a DataFrame\n",
    "    print(df.head())  # Print the first few rows of the DataFrame for debugging\n",
    "\n",
    "\n",
    "agrimet_locations()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
